---
---


@STRING{CVPR = {CVPR}}
@STRING{ECCV = {ECCV}}
@STRING{ICCV = {ICCV}}
@STRING{NEURIPS = {NeurIPS}}
@STRING{ARXIV = {arXiv}}
@STRING{ICLR = {ICLR}}

@inproceedings{xu2024videogigagan,
  title={VideoGigaGAN: Towards Detail-rich Video Super-Resolution},
  author={Xu, Yiran and Park, Taesung and Zhang, Richard and Zhou, Yang and Shechtman, Eli and Liu, Feng and Huang, Jia-Bin and Liu, Difan},
  booktitle=ARXIV,
  year={2024},
  html = {https://videogigagan.github.io/},
  pdf = {https://arxiv.org/abs/2404.12388},
  img = {assets/img/publications/videogigagan_teaser.mp4},
  supp={https://videogigagan.github.io/assets/supp.pdf},
  tldr={VideoGigaGAN is a video super-resolution method that produces up to 8x high-resolution frames with fine-grained details.},
}

@inproceedings{xu2024innout,
  title={In-N-Out: Faithful 3D GAN Inversion with Volumetric Decomposition for Face Editing},
  author={Xu, Yiran and Shu, Zhixin and Smith, Cameron and Oh, Seoung Wug and Huang, Jia-Bin},
  booktitle=CVPR,
  year={2024},
  html={https://in-n-out-3d.github.io/},
  pdf={http://arxiv.org/abs/2302.04871},
  img={assets/img/publications/in-n-out_teaser.mp4},
  supp={https://in-n-out-3d.github.io/static/images/supp.pdf},
  tldr={In-N-Out is a 3D GAN inversion method that decomposes the input into two components enabling the inversion for Out-of-Distribution data.},
}

@inproceedings{qiao2023dynamic,
  title={Dynamic Mesh-aware Radiance Fields},
  author={Qiao, Yi-Ling and Gao, Alexander and Xu, Yiran and Feng, Yue and Huang, Jia-Bin and Lin, Ming},
  booktitle=ICCV,
  year={2023},
  html={https://mesh-aware-rf.github.io/},
  pdf={https://arxiv.org/abs/2309.04581},
  img={assets/img/publications/dmrf.gif},
  tldr={DMRF is a hybrid 3D representation that enables simulation based on NeRFs.},
}

@inproceedings{liao2023text,
  title={Text-driven Visual Synthesis with Latent Diffusion Prior},
  author={Liao, Ting-Hsuan and Ge, Songwei and Xu, Yiran and Lee, Yao-Chih and AlBahar, Badour and Huang, Jia-Bin},
  booktitle=ARXIV,
  year={2023},
  html={https://latent-diffusion-prior.github.io/},
  pdf={https://arxiv.org/abs/2302.08510},
  img={assets/img/publications/latent-diffusion-prior.gif},
  tldr={We leverage latent diffusion priors for multiple text-driven visual synthesis tasks.},
}

@inproceedings{xu2022temporally,
  title={Temporally Consistent Semantic Video Editing},
  author={Xu, Yiran and AlBahar, Badour and Huang, Jia-Bin},
  booktitle=ECCV,
  year={2022},
  html={https://video-edit-gan.github.io/},
  pdf={https://arxiv.org/abs/2206.10590},
  img={assets/img/publications/videogan_teaser.gif},
  tldr={We propose a video editing method that enables semantic manipulation with temporal consistency.},
}

@inproceedings{xu2020explainable,
  title={Explainable Object-Induced Action Decision for Autonomous Vehicles},
  author={Xu, Yiran and Yang, Xiaoyin and Gong, Lihang and Lin, Hsuan-Chu and Wu, Tz-Ying and Li, Yunsheng and Vasconcelos, Nuno},
  booktitle=CVPR,
  year={2020},
  html={https://twizwei.github.io/bddoia_project/},
  pdf={https://arxiv.org/abs/2003.09405},
  img={assets/img/publications/xoia.png},
  tldr={We propose an explainable decision-making framework for autonomous vehicles.},
}
